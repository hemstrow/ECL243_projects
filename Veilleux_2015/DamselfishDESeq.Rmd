---
title: "Damselfish_DESeq""
author: "Amanda"
date: "2/16/2018"
output: html_document
---

Download DESeq from Bioconductor: 
```{r, eval=F}
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("DESeq2")
```

Load DESeq2:
```{r}
library("DESeq2")
```

Load count data file into R (sample ID row included):
```{r}
counts <- as.matrix(read.csv("~/Documents/Davis/Classes/ECL243/Damselfish_data/readCount.csv", row.names="gene_id"))
```

Load sample information table into R: 
```{r}
sampleinfo <- read.csv("~/Documents/Davis/Classes/ECL243/Damselfish_data/sample_metadata.csv", stringsAsFactors = FALSE)

#make a new column that has a grouping variable:
library(stringr)
library(dplyr)
sampleinfo2 <- sampleinfo%>%
  mutate(group=str_c(Treatment, F1.Temperature, F2.Temperature, sep="."))

#Use sample names as rownames:
rownames(sampleinfo2) <- sampleinfo2$symbol

```

Create a DESeq2 object (dds):
```{r}

colnames(counts) <- NULL  #note, this is added b/c there is a known error after the latest update where the column names of the count file are different than the row names of the metadata file (error: "assay colnames() must be NULL or equal colData rownames()") Even though these PERFECTLY MATCH for our files, it's still generating this error. So it can be fixed by clearing out the column names of the count files.

dds <- DESeqDataSetFromMatrix(countData = counts,
                              colData = sampleinfo2,
                              design = ~ group)
#using design by "group", which includes treatment, f1 temp, and f2 temp.

dds

```

Remove genes with less than 1 count across all data:
```{r}
dds1 <- dds[rowSums(counts(dds)) > 1, ]
dds2 <- dds1

#We filtered to >1 read to keep as many reads as possible. The pipeline filters to >10 reads. Not sure what the authors did. 

#keep <- rowSums(counts(dds)) >= 10
#dds2 <- dds[keep,]

```

Specifying the factor level (you want to order everything to start with control because that's what it's comparing against):
```{r}
str(counts)
str(sampleinfo2)

dds2$group <- factor(dds2$group, levels= c("Control.+0°C.+0°C", "Developmental.+0°C.+1.5°C", "Developmental.+0°C.+3°C", "Transgenerational.+1.5°C.+1.5°C", "Transgenerational.+3°C.+3°C"))

```

Drop levels without samples:
```{r}
dds2$group <- droplevels(dds2$group)
```


Normalization/variance stabilization: 
```{r}
#rlog is the normalization. We only want to use this for visualization, NOT for the differential expression analysis. 

#rld takes a while to run. 
rld <- rlog(dds, blind=FALSE)
```

Starting to visualize...:
```{r}

sampleDists <- dist(t(assay(dds2)))

library("pheatmap")
library("RColorBrewer")

sampleDistMatrix <- as.matrix(sampleDists)
rownames(sampleDistMatrix) <- dds2$group
colnames(sampleDistMatrix) <- NULL
colors <- colorRampPalette(rev(brewer.pal(9, "Blues")))(225)
pheatmap(sampleDistMatrix, 
         clustering_distance_rows = sampleDists, 
         clustering_distance_cols = sampleDists, 
         col=colors)

library("ggplot2")
plotPCA(dds2, intgroup = c("Treatment", "F1.Temperature", "F2.Temperature"))

pcaData <- plotPCA(rld, intgroup = c("Treatment", "F1.Temperature", "F2.Temperature"), returnData=TRUE)
pcaData

percentVar <- round(100 * attr(pcaData, "percentVar"))

ggplot(pcaData, aes(x=PC1, y=PC2, color=group, shape=Treatment)) +
  theme_bw() +
  geom_point(size=3) + 
  xlab(paste0("PC1: ", percentVar[1], "% variance")) +
  ylab(paste0("PC2: ", percentVar[2], "% variance")) +
  coord_fixed()

```


Running the DESeq analysis:
```{r}
dds2 <- DESeq(dds2)
res <- results(dds2)
##res <- results(dds2, contrast=c("group"))   ##add pairwise comparisons

## If we use the contrast "group", we compare each treatment to the control (4 total comparisons). BUT, the authors also compared the developmental to the transgenerational for each temperature (6 comparisons total). So, we have to specify each comparison. Then, we take all the genes that are significantly differentially expressed in at least one of those comparisons, and use those for our contig file to BLAST. 

res1 <- results(dds2, contrast=c("group", "Control.+0°C.+0°C", "Developmental.+0°C.+1.5°C"), alpha=0.05, lfcThreshold = 1.5)

res1[order(res1$padj),]
summary(res1)
#res1sig <- which(res1[,6]<0.05)
#siggenes <- as.data.frame(subset)
siggenes1 <- subset(rownames(res1), res1$padj < 0.05)
summary(siggenes1)

res2 <- results(dds2, contrast=c("group", "Control.+0°C.+0°C", "Developmental.+0°C.+3°C"), alpha=0.05, lfcThreshold = 1.5)

res2[order(res2$padj),]
summary(res2)
siggenes2 <- subset(rownames(res2), res2$padj < 0.05)
summary(siggenes2)

res3 <- results(dds2, contrast=c("group", "Control.+0°C.+0°C", "Transgenerational.+1.5°C.+1.5°C"), alpha=0.05, lfcThreshold = 1.5)

res3[order(res3$padj),]
summary(res3)
siggenes3 <- subset(rownames(res3), res3$padj < 0.05)
summary(siggenes3)

res4 <- results(dds2, contrast=c("group", "Control.+0°C.+0°C", "Transgenerational.+3°C.+3°C"), alpha=0.05, lfcThreshold = 1.5)

res4[order(res4$padj),]
summary(res4)
siggenes4 <- subset(rownames(res4), res4$padj < 0.05)
summary(siggenes4)

res5 <- results(dds2, contrast=c("group", "Developmental.+0°C.+1.5°C", "Transgenerational.+1.5°C.+1.5°C"), alpha=0.05, lfcThreshold = 1.5)

res5[order(res5$padj),]
summary(res5)
siggenes5 <- subset(rownames(res5), res5$padj < 0.05)
summary(siggenes5)

res6 <- results(dds2, contrast=c("group", "Developmental.+0°C.+3°C", "Transgenerational.+3°C.+3°C"), alpha=0.05, lfcThreshold = 1.5)

res6[order(res6$padj),]
summary(res6)
siggenes6 <- subset(rownames(res6), res6$padj < 0.05)
summary(siggenes6)

combinedresults <- c(siggenes1, siggenes2, siggenes3, siggenes4, siggenes5, siggenes6)
summary(combinedresults)

#Merge all of the res objects for each comparison for the differential expression file. 
res <- rbind(cbind(res1, comp = "CxD1.5"), cbind(res2, comp = "CxD3"), cbind(res3, comp="CxT1.5"), cbind(res4, comp="CxT3"), cbind(res5, comp="D1.5vT1.5"), cbind(res6, comp = "D3vT3"))

res <- as.data.frame(res)

#INCLUDE WILL'S FILTERING HERE! 

saveRDS(res, "./Damselfish_data/res.RDS")

##Check for duplications:

deduped <- combinedresults[!duplicated(combinedresults[,1]),]

library(dplyr)
combinedresults <- as.data.frame(combinedresults)
significantcontigs <- rownames(combinedresults) %>% distinct(.keep_all = TRUE)
detach("package:dplyr", unload=TRUE)
write.csv(significantcontigs, sep=",", "significantcontigs")

#Note, the "res" functions take a few minutes to run:
resultsNames(dds2)
res <- lfcShrink(dds2, coef=2)

resLFC <- lfcShrink(dds2, coef=2)


library("BiocParallel")
register(MulticoreParam(4))

resOrdered <- res[order(res$padj),]

summary(res)

#How many adjusted p-values were less than 0.1?
sum(res$padj <0.1 na.rm=TRUE) #This didn't work

res05 <- results(dds2, alpha=0.05)
summary(res05)
```

Independent Hypothesis Weighting to filter p-values: 
```{r}
#Install and load IHW:
source("https://bioconductor.org/biocLite.R")
biocLite("IHW")
library("IHW")


resIHW <- results(dds2, filterFun=ihw)
summary(resIHW)
sum(resIHW$padj < 0.1, na.rm=TRUE)
metadata(resIHW)$ihwResult

```

Exploring and exporting results: MA plot. This shows the log2 fold changes attribuatable to a given variable over th emean of normalized counts for all the samples in the DESeqDataSet
```{r}
plotMA(res, ylim=c(-2,2))

plotMA(resLFC, ylim=c(-2,2)) #this didn't seem to work :( por que?

idx <- identify(res$baseMean, res$log2FoldChange)
rownames(res)[idx]
```

Alternative shrinkage estimators: Do we want to use any of these...????
```{r}
resApe <- lfcShrink(dds2, coef=2, type="apeglm")
resAsh <- lfcShrink(dds2, coef=2, type="ashr")
par(mfrow=c(1,3), mar=c(4,4,2,1))
xlim <- c(1,1e5); ylim <- c(-3,3)
plotMA(resLFC, xlim=xlim, ylim=ylim, main="normal")
plotMA(resApe, xlim=xlim, ylim=ylim, main="apeglm")
plotMA(resAsh, xlim=xlim, ylim=ylim, main="ashr")
```

Plot counts:
```{r}
plotCounts(dds2, gene=which.min(res$padj), intgroup="group")

d <- plotCounts(dds2, gene=which.min(res$padj), intgroup="group", 
                returnData=TRUE)
library("ggplot2")
ggplot(d, aes(x=group, y=count)) + 
  geom_point(position=position_jitter(w=0.1,h=0)) + 
  scale_y_log10(breaks=c(25,100,400))
```


Data transformations and visualization:
```{r}

#DO NOT DO VST OR RLOG --- NOT INTENDED FOR DE. 
vsd <- vst(dds2, blind=FALSE)  ##some sort of variance stabilized transformation
rld <- rlog(dds2, blind=FALSE)  ##some sort of log normalization 
head(assay(vsd),3)

ntd <- normTransform(dds2)
library("vsn")
meanSdPlot(assay(ntd))

meanSdPlot(assay(vsd))

meanSdPlot(assay(rld))
```

Heatmap:
```{r}
library("pheatmap")
select <- order(rowMeans(counts(dds2, normalized=TRUE)), 
                decreasing=TRUE)[1:20]
df <- as.data.frame(colData(dds2)["group"])
pheatmap(assay(ntd)[select,], cluster_rows=FALSE, show_rownames=FALSE, 
         cluster_cols=FALSE, annotation_col=df)

pheatmap(assay(ntd)[select,], cluster_rows=TRUE, show_rownames=FALSE, 
         cluster_cols=TRUE, annotation_col=df)
```


Using the new BLAST-ed file that Will generated (BLASTn, nr/nt):
```{bash}
#Copy BLAST-ed file from the FARM to my local computer: 
scp mfrazier@farm.cse.ucdavis.edu:/home/mfrazier/damselfish/bn_out.txt /Users/amanda/Documents/Davis/Classes/ECL243/Damselfish_data
```

```{r}
blastn <- read.delim("Damselfish_data/bn_out.txt", sep="\t", stringsAsFactors = FALSE)

#These are the column names for any BLAST file. What we care about is the bitscore and the qseqid. 
colnames(blastn) <- c("qseqid", "sseqid", "pident", "length", "mismatch", "gapopen", 
                       "qstart", "qend", "sstart", "send", "evalue", "bitscore")

length(unique(blastn$qseqid))

#The qseqid is the querey (e.g. gene) sequence id. 
#The sseqid is the subject (e.g. reference genome) sequence id. 
#Order the columns first based on the contig, then on the evalue. 
blastn_ordered <- blastn[order(blastn$qseqid, blastn$evalue), ]
    
#Select the last row by id
blastn_best <- blastn[!duplicated(blastn$qseqid, fromLast=TRUE), ]


#will
blastn_ordered$sseqid <- sub("\\..*", "", blastn_ordered$sseqid)
u_sseqid <- unique(blastn_ordered$sseqid)

ensembl <- useMart("ensembl")

mo <- getBM(c("sseqid", "go_id"), values = u_sseqid, mart = ensembl)


#Get rid of everything after the period, this is what we want to search in uniprot:
blastn_best_sseqid <- gsub("\\..*", "", blastn_best_sseqid) 
blastn_sseqid <- gsub("\\..*", "", blastn_ordered$sseqid)
blastn_sseqid <- unique(blastn_sseqid)
write(blastn_sseqid, "blastn_sseqid")

blastn_best_sseqid

write(blastn_best_sseqid, "blastn_best_sseqid")

#How many duplicate sseqid's do we have from the BLAST search? Should we remove these?
deduped_blastn_best_sseqid <- !duplicated(blastn_best_sseqid)

table(deduped_blastn_best_sseqid)["FALSE"]
```


```{r}

mres <- readRDS("./Damselfish_data/mres.RDS")

```


Back to the figures.....

Heatmap:
```{r}
library("pheatmap")
select <- order(rowMeans(counts(dds2, normalized=TRUE)), 
                decreasing=TRUE)[1:20]
df <- as.data.frame(colData(dds2)["group"])
pheatmap(assay(ntd)[select,], cluster_rows=FALSE, show_rownames=FALSE, 
         cluster_cols=FALSE, annotation_col=df)

pheatmap(assay(ntd)[select,], cluster_rows=TRUE, show_rownames=FALSE, 
         cluster_cols=TRUE, annotation_col=df)
```

